name: Streams height data processing workflow

on:
  schedule:
    - cron: '0 * * * *'  # Runs every hour at the top of the hour
  workflow_dispatch:  # Allows for manual triggering

jobs:
  data_processing_job:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas geopandas requests ftplib

      - name: Run Data Processing Script
        env:
          FTP_HOST: "ftp.bom.gov.au"
          FTP_DIRECTORY: "/anon/gen/fwo/"
          STATION_URL: "http://reg.bom.gov.au/catalogue/rain_river_station_list.csv"
        run: python scripts/stream_data_process.py

      - name: Upload Datasets to Repository
        uses: actions/upload-artifact@v2
        with:
          name: datasets
          path: datasets
